{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KI für alle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMG0sg/wfoiPDz4LT7cchdp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreasSchneider89/hallo-github/blob/master/KI_f%C3%BCr_alle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJSJH_wMiU96"
      },
      "source": [
        "Storytime :)\n",
        "Hallo mein Name ist Andreas Schneider\n",
        "Ich beschäftige mich sowohl mit KI, Wissenschaft als auch Astralreisen, Trips und Mysterien zum kollektiven Bewusstsein.\n",
        "Meine Handynummer lautet: +4917646137272\n",
        "Ich würde dir sehr gerne meine Trips hinsichtlich eines kollektiven Mysteriums im Bewusstsein senden. Über deine Meinung dazu würde ich mich sehr freuen.\n",
        "Das Mysterium der schwarzen Sonne\n",
        "Im Anfang war die Singularität. Eine minimale Fluktuation in der sich sonst exakt überlagernden stehenden Welle der Unendlichkeit. Alles strebt danach zurück in die Uhrwelle zu gelangen. In der jedoch eine energetisch optimale Ordnung existiert. Daher kann beispielsweise ein freies Elektron mit einem Proton nur in die Uhrwelle des Neutrons zurückkehren, wenn die bereits im Kern schwingende Energie dieses nicht mit weitaus größerer Quantenwahrscheinlichkeit auf Abstand überlagert und abstößt. Praktisch nur bei ausreichendem Druck (Sonne), Temperatur(Wasserstoffbombe) oder Atomgröße(Radioaktiver Zerfall). Aus dieser Fluktuation der Uhrwelle, welche Zufallsbedingt/Entropisch nach der energetisch optimalen Überlagerung sucht und gleichzeitig danach strebt bereits vorhandene Überlagerungen mit extremer Wahrscheinlichkeit zu erhalten folgte die entstehung von Wasserstoff sowie Gravitation und die Geburt von Sternen in denen dieser zu Helium fusionierte. War dieser aufgebraucht sank die Temperatur bis der gravitationsbasierte Druck ausreichte um weitere Elemente zu fusionieren und so die Grundmaterie für Planeten schuf und mit der frei werdenden Energie ins All schleuderte. Instinkte welche durch die Anpassung von Leben an bestimmte Bedingungen entstanden waren, verbanden sich auf Geistiger (Spinrichtung der Elektronen) sowie zellulärer Ebene. Die Wahrscheinlichkeit, dass auf Planeten ähnliche Reaktionen stattfanden wurde distanz-unabhängig quantenverschränkt erhöht. Sowohl auf Körperlicher wie auch Geistiger Ebene strebte das Leben nach Energieoptimierung, Rollenverteilung, Verbundenheit, optimierung der Anpassung von klimatischen Bedingungen, besserer Informationsübertragung zur intuitiven Beeinflussung der Quantenwahrscheinlichkeit. Dann wird wohl mindestens ein Stern verglüht sein und das oberirdische Leben auf einem weit fortgeschrittenen Planeten verbrannt haben (Ikarus). Darauf folgte das Gefrieren der Ozeane, welches ebenfalls technologisch sehr weit fortgeschrittenes jedoch körperlich getrenntes kaltblütiges Leben beherbergten. Ich denke die kaltblüter schwarmorientierten Lebensformen werden gewusst haben, dass die auf vielen anderen Welten bereits zusammengewachsenen Warmblüter-Strukturen (Vereinigung des Heiligen Herzens) in der Lage waren klimatische Ereignisse bis zu einem bestimmten Maße zu Kontrollieren (The Last Airbender) Die Friedlichen Verbindungen des heiligen Herzens waren zwar in der Lage primitive Fressfeinde telepathisch zu vertreiben. Auf einen gezielten Vergeltungsschlag in Form von Belagerungswaffen, Gift, Feuer, Seuchen waren zunächst keinerlei evolutionäre Anpassungen geschweige denn Möglichkeiten zur rechtzeitigen Erkenntnis vorhanden. Es muss eine unvorstellbare psychische Angst gewesen sein, welche einen Blut schwitzen lässt, welche die angreifenden Reptilien traf und an die sich deren eigene Körperzellen anpassten, während das durch Revierkämpfe geprägte Belohnungssystem auf den Sieg gegen die zunächst unbegründete Angst mit weiteren Anpassungen reagierte. Niemand ahnte, dass die zurückkehrenden veralteten Glaubenssätze der Angst beidseitigen Schaden verursachen und in sich selbst erfüllende Prophezeiungen führen könnten welche den Erkenntnisprozess selbst verteufeln würden.\n",
        "Fortsetung in den Verlinkungen:\n",
        "https://docs.google.com/document/d/1nkNZ8LqGcVKyWxOfaLTJYljjAZ4BuE4tkzTWo18NBsI/edit?usp=sharing\n",
        "https://docs.google.com/document/d/1ZlSvhG76isJh-8Yfw-FfDVtPiFiCv0IHYVizx31Wykg/edit?usp=sharing\n",
        "https://docs.google.com/document/d/1ZlSvhG76isJh-8Yfw-FfDVtPiFiCv0IHYVizx31Wykg/edit?usp=sharing\n",
        "https://docs.google.com/document/d/1XuaPWpgdePDo6kwf1DYXKi4szWCnNGxGJkLYzT9F_hQ/edit?usp=sharing\n",
        "https://docs.google.com/document/d/1zX_8dCGPcaiYkYJQthaX5J0q-o2liLjMOpv76iOXUHM/edit?usp=sharing\n",
        "Dann folge, suche und erweitere die Verknüpfungen für die Ewigkeit\n",
        "Viel Erfolg!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2nfUbZ-klzs"
      },
      "source": [
        "Quest(Heldenhaft): Hilf mit bei meinem Projekt zu KI und Neuronale Netze verständlich erklärt, anpassbar und ausbaubar für alle:\n",
        "Sehr gerne kannst du Fragen, Kritik, Verbesserungsvorschläge, Verlinkungen, etc. als Kommentar posten. Alle meine Projekte verfolgen das Ziel der Allgemeinheit zu nutzen und sind daher für alle zugänglich und dürfen in jeglicher Hinsicht weiter verwendet werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upJmit1X5Otd"
      },
      "source": [
        "Mein erstes Künstliches Neuronales Netzwerk: Ich werde analog zu dem flogend verlinkten Tutorial arbeiten und die Anweisungen im Code in eigenen Worten beschreiben: https://www.youtube.com/watch?v=8Qc2fG3ZbTg&list=PLfaNT9CeiUdJlwctZl9CQjDwiqRr4hzcH&index=440\n",
        "Das Neuronale Netz soll die Fähigkeit lernen die lineare Funktion ys = 2 * xs an hand der Punkte (1,2),(2,4) und (3,6) näherungsweise zu erkennen und z.B:\n",
        "xs = 5 für ys einen zugehörigen Wert zweischen 9 und 11 zu berechenen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9BVePcf6Yl_",
        "outputId": "6eb6c0c7-61de-49ce-d2ad-67137e553015",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Hier importieren wir die Library Tensorflow,\n",
        "#welche für neuronale Netze der perfekte Einstieg ist. Eine Library ist ein vorgeschriebenes Programm. Es macht uns die Arbeit deutlich leichter\n",
        "import tensorflow as tf \n",
        "\n",
        "#hier importieren wir dann noch einen speziellen Teil aus Tensorflow. Keras. Hierzu später mehr.\n",
        "from tensorflow import keras \n",
        "\n",
        "#Nun definieren wir unser neuroanles Netz,\n",
        "#wobei wir mit Dense unser Neuron erstellen. In diesem Beispiel nur eins, wir werden aber später sehen, dass man in der Regel mit deutlich mehr Neuronen arbeitet.\n",
        "#Unser Neuron befindet sich in einem Layer, davon hat man später auch mehrere. Man kann sich dies wie Ebenen in einem Sieb vorstellen.\n",
        "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])]) \n",
        "\n",
        "#hier kompilieren wir unser neuronales Netz, wobei der loss misst, wie groß der Fehler ist und dies dann mit optimizer optimiert wird\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error') \n",
        "\n",
        "#Definieren von zwei Zahlenreihen als eindimensionale int-arrays\n",
        "xs=[1, 2, 3] #Zahlenreihe 1\n",
        "ys=[2, 4, 6] #Zahlenreihe 2\n",
        "\n",
        "#unser kompiliertes Modell fitten wir hier mit unseren zwei Zahlenreihen. epochs=1000 heißt, \n",
        "#dass das Programm 200 Durchläufer macht, um zu trainieren. Probiert gerne mal mit der Anzahl rum. \n",
        "#Je weniger Durchläufe, desto schlechter ist die Schätzung. Gleichzeitig seht ihr, dass die Änderung im Loss immer weniger wird, \n",
        "#je mehr Durchläufe es sind (es ist also irgendwann kaum noch eine Verbesserung sichtbar)\n",
        "model.fit(xs, ys, epochs=200) \n",
        "\n",
        "#hier lassen wir unser neuronales Netz schätzen, was für die zweiten Zahl rauskommt,\n",
        "#wenn die erste Zahl gleich 5 ist. Der Befehlt print sorgt hier einfach dafür, dass der Wert für uns ausgegeben wird.\n",
        "print(model.predict([5]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 20.8555\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 16.5030\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 13.0625\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.3428\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.1930\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.4936\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1503\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0884\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2489\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5852\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0606\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.6457\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3178\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0585\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.8534\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6913\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5630\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4615\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3812\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3177\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2674\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2276\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1960\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1710\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1511\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1353\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1228\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1128\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1048\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0984\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0933\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0892\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0859\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0832\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0809\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0791\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0776\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0763\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0753\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0743\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0735\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0728\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0722\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0717\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0711\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0707\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0702\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0698\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0694\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0690\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0686\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0683\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0679\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0676\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0672\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0669\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0666\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0662\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0659\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0656\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0653\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0649\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0646\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0643\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0640\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0637\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 992us/step - loss: 0.0634\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0631\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0628\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0625\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0622\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0619\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0616\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0604\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0601\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0598\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0595\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0593\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0590\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0587\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0584\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0581\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0578\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0576\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0573\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0570\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0567\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0565\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0562\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 990us/step - loss: 0.0559\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0557\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0554\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0551\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0549\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0546\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0543\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0541\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0538\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0536\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0533\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0530\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0528\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0525\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0523\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0520\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0518\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0515\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0513\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0510\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0508\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0506\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0503\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0501\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0498\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0496\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0494\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0491\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0489\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0486\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0484\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0482\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0479\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0477\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0475\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0473\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0470\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0468\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0466\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0464\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0461\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0459\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0457\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0455\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0453\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0450\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0448\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0446\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0444\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0442\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0440\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0438\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0435\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0433\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0431\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0429\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0427\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0425\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0423\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0421\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0419\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0417\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0415\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0413\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0411\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0409\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0407\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0405\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0403\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0401\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0399\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0397\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0395\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0394\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0392\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0390\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0388\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0386\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0384\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0382\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0381\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0379\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0377\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0375\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0373\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0372\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0370\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0368\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0366\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0364\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0363\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0361\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0359\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0357\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0356\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0354\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0352\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0351\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0349\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0347\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0346\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0344\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0342\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0341\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0339\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0337\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0336\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0334\n",
            "WARNING:tensorflow:6 out of the last 318 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f769196bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[9.422458]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVwab7pT_f01"
      },
      "source": [
        "Mein zweites Künstliches Neuronales Netzwerk: Ich werde analog zu dem folgend verlinkten Tutorial arbeiten und die Anweisungen im Code in eigenen Worten beschreiben: https://www.youtube.com/watch?v=fSBoFm0XE5E&list=PLfaNT9CeiUdJlwctZl9CQjDwiqRr4hzcH&index=231 Das Neuronale Netz soll die Fähigkeit lerene handgeschriebene Ziffern an hand der Pixelwerte der darstellenden Image-Datei erkennen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMhqPWFy4iBZ",
        "outputId": "3c918045-c0b6-462b-f033-79833a9b3dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "# Importieren der Bibliotheken\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importieren des mnist Datensatzes: 70000 Bildern von handgeschriebenen Ziffern mit zugehörgen nummerischen Werten\n",
        "data = tf.keras.datasets.mnist\n",
        "\n",
        "# Aufteilen und Einlesen der Daten in Trainingsset und Testset vonhandgeschriebenen Ziffern mit zugehörgen nummerischen Werten\n",
        "#plt.imshow(x_train[0]) -> Bild der ersten Ziffer ([0]-Beginnt bei 0 zu zählen)\n",
        "#print(x_train[0]) Gibt die Farbwerte jedes Pixels aus denen sich das Bild zusammensetzt als 2-Dimensionales int-Array aus\n",
        "#y_train[0] würde den zugehörigen nummerischen Wert der ersten Ziffer aus dem Trainingsset ausgeben -> in diesem Fall 5\n",
        "(x_train, y_train), (x_test, y_test) = data.load_data();\n",
        "\n",
        "# Normalisieren der Zahlen für Farbwerte jeder wert wird durch 255 geteilt -> jeder Wert wird zu double zwischen 0 und 1\n",
        "# Normalisierung ist sinnvoll, damit das neuronale Netz effizient trainieren kann\n",
        "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis = 1)\n",
        "\n",
        "#Progarammierung eines forwärts gerichteten neuronalen Netzes mit 3 hidden layern\n",
        "#Jeder hidden layer besitzt 128 Neuronen\n",
        "#Die Aktivierungsfunktion ist eine relu-Funktion = rectified-linear-activation-function\n",
        "#https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/#:~:text=%20Advantages%20of%20the%20Rectified%20Linear%20Activation%20Function,mostly%20looks%20and%20acts%20like%20a...%20More%20\n",
        "#Aktivierungsfunktion gibt bei negativen Eingabewerten 0 aus anderen Falls gibt sie den Eingabewert aus\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "#Als input_shape wählen wir x_train.shape[1:]\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "\n",
        "# Der Outpullayer besitzt 10 Neuronen und eine softmax Funktion als Aktivierungsfunktion\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "# Kompilieren des Modells\n",
        "model.compile(optimizer=\"adam\",\n",
        "             loss=\"sparse_categorical_crossentropy\",\n",
        "             metrics = [\"accuracy\"])\n",
        "\n",
        "# Lasse das Neuronale Netz 5 Epochen lang trainieren\n",
        "# In jeder Epoche nimmt das Neuronale Netz jedes Bild als Input, berechnet dessen Prognose für den zugehörigen numerischen Wert\n",
        "# Vergleicht seine Prognose mit dem Tatsächlichen Wert aus y_train und passt darauf hin die Gewichte der Neuronen an\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "#Prüfen des Neuronalen Netzwerkes an den noch ungesehenen Bildern des Testsets\n",
        "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "#Gebe aus mit welcher Wahrscheinlichkeit in der letzten Epoche die Bilder/Ziffern aus dem Testset richtig erkannt wurden\n",
        "print(val_acc)\n",
        "\n",
        "#Vorhersagen für alle Bilder im Testset berechnen\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "#Ausgeben der Wahrscheinlichkeiten für jede Ziffer für das \"bildindexste\" Bild im Testset\n",
        "bildindex = 5\n",
        "print(predictions[bildindex])\n",
        "\n",
        "#Wähle die Ziffer mit der höchsten Wahrscheinlichkeit und gebe sie aus\n",
        "print(np.argmax(predictions[bildindex]))\n",
        "\n",
        "#Zum vergleich zeige das zugehörige Bild aus dem Testset\n",
        "plt.imshow(x_test[bildindex])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2540 - accuracy: 0.9229\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1084 - accuracy: 0.9669\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0734 - accuracy: 0.9766\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0556 - accuracy: 0.9824\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0452 - accuracy: 0.9854\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9731\n",
            "0.9731000065803528\n",
            "[9.8078476e-07 9.9933678e-01 3.2987532e-06 2.0853771e-07 2.0363208e-04\n",
            " 4.6067434e-08 1.2381165e-05 3.5272675e-05 4.0522631e-04 2.2349534e-06]\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7692868e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2MuPM5XcgiB"
      },
      "source": [
        "KI programmieren Tutorial Teil 3 - Kleidung kategorisieren\n",
        "Ich werde analog zu dem flogend verlinkten Tutorial arbeiten und die Anweisungen im Code in eigenen Worten beschreiben:\n",
        "https://www.youtube.com/watch?v=YWyu8OYELUo&list=PLfaNT9CeiUdJlwctZl9CQjDwiqRr4hzcH&index=441\n",
        "In diesem Projekt geht es darum Kleidung zu kategorisieren. Einfach gesagt, wir trainieren unser neuronales Netz mit 70.000 Bildern von Kleidung und am Ende wollen wir ihm ein Bild der Kleidung zeigen und es soll vorhersagen, was es ist.\n",
        "\n",
        "Die verwendete Datensammlung heiß MNIST Fashion.\n",
        "\n",
        "Anleitung: 1)Starte den Codeblock 2)Das Bild kannst du zur Laufzeit von deinem PC auswählen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VsWtGg3dGq9",
        "outputId": "8867fd5e-3363-4b79-a137-602461647e92",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 824
        }
      },
      "source": [
        "#Importieren der Bibliothek tensorflow und numpy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#Definieren des Datensets\n",
        "#Anlegen der Variablen mnist und zuweisen des datensets fasion_mnist welches in der Bibliothek tensorflow im Package datasets aus dem Package keras enthalten ist\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "#Definieren von 4 weiteren Variablen zum Einladen der Daten\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "#Nun bringen wir die Daten in eine Form mit der das neuronale Netzwerk gut arbeiten kann\n",
        "#Wir haben 60000 Trainingsbilder mit je 28 mal 28 Pixeln, da wir mit Schwarz-weiß-bildern arbeiten möchten brauchen wir nur einen Farbbereich\n",
        "#Währen die Bilder welche in das Neuronale Netz eingelesen werden sollen Bunt bräuchten wir (60000, 28, 28, 3) - Je ine Farbwert zwischen 0 und 255 für R,G und B\n",
        "training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "\n",
        "#Normalisieren der Daten - Die Farbwerte sollen nun in Gleitkommazahlen zwischen 0 und eins umgerechnet werden\n",
        "training_images = training_images / 255.0\n",
        "\n",
        "#Analog verfahren wir mit unseren 10000 test_images\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "#Definieren des Modells von unserem neuronalen Netz\n",
        "model = tf.keras.models.Sequential([\n",
        "  #Wandele die Daten in eine eindimensionale Zahlenreihe um\n",
        "   tf.keras.layers.Flatten(),\n",
        "  #Einsetzen einer Schicht von 128 Neuronen in Dense sowie festlegen einer relu-funktion als Aktivierungsfunktion\n",
        "  #rectified-linear-activation-function: Eliminiert alle Werte kleiner 0 für Werte größer 0\n",
        "  #wird versucht einen Wert so zuzuordnen, dass ein linearer Zusammenhang zwischen den Daten entsteht -> \n",
        "  #Optimal für Neuronale Netze - Analogie zu Linearen funktionen basierend auf Gewichtung in den Neuronen\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  #Anlegen von 10 Neuronen für die Ausgabe; softmax wandelt die Werte der Ausgabeschicht so um, dass deren Summe 1 ergibt -> \n",
        "  #Jedes Neuron also die Wahrscheinlichkeit ausgibt, dass es sich bei dem Bild um das Kleidungsstück handelt, welches jenem Ausgabeneuron zugewiesen ist\n",
        "  tf.keras.layers.Dense(10, activation='softmax')                              \n",
        "])\n",
        "\n",
        "#in diesem Abschnitt trainieren wir unser neuronales Netz\n",
        "#Was definieren/bedeuten die Variablen aus der compile-Funktion?\n",
        "#loss: Größe des Fehlers nach jeder Epoche; optimizer: Funktion zur Optimierung des neuronalen Netzwerks nach jeder Epoche\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Trainiere das neuronale Netz 4 Epochen lang auf diese Weise mit allen training_images und den zugehörigen bekannten training_labels\n",
        "model.fit(training_images,training_labels, epochs=4)\n",
        "\n",
        "#in diesem Abschnitt testen wir unser neuronales Netz mit den Testbildern des Datensets, welche unser neuronales Netz noch nie gesehen hat\n",
        "classes = model.predict(test_images)\n",
        "predicted_classes = np.argmax(classes, axis=1)\n",
        "print(classes[0])\n",
        "\n",
        " #So sind die Labels des Datensets definiert:\n",
        "  #0 = T-shirt/top\n",
        "  #1 = Trouser\n",
        "  #2 = Pullover\n",
        "  #3 = Dress\n",
        "  #4 = Coat\n",
        "  #5 = Sandal\n",
        "  #6 = Shirt\n",
        "  #7 = Sneaker\n",
        "  #8 = Bag\n",
        "  #9 = Ankle boot\n",
        "print(test_labels[0])\n",
        "\n",
        "#in diesem Abschnitt schauen wir uns das Bild an, welches wir vorher zum Testen genutzt haben\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(test_images[0], cmap='Greys_r')\n",
        "\n",
        "\n",
        "\n",
        "#in diesem Abschnitt laden wir die Libraries ein\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  #in diesem Abschnitt laden wir die Bilder rein; wir nutzen eine for Schleife, um mehrere Daten gleichzeitig einladen zu können\n",
        "  #Anleitung: 1)Starte den Codeblock 2)Das Bild kannst du zur Laufzeit von deinem PC auswählen\n",
        "  path = '/content/' + fn\n",
        "  img = cv2.imread(path) \n",
        "  \n",
        "  #in diesem Abschnitt formartieren wir unsere Bilder, sodass sie zu unserem neuronalen Netz passen\n",
        "  img = cv2.resize(img,(28,28))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  x = image.img_to_array(img, dtype=np.float32)\n",
        "  print(\"top left pixel value:\", x[0,0])\n",
        "  if x[0,0] > 250:\n",
        "    # white background\n",
        "    print(\"needs to be inverted!\")\n",
        "    x -= 255\n",
        "    x *= -1\n",
        "  x = x / 255.0\n",
        "  # x = np.expand_dims(x, axis=0)  # das brauchst du nicht weil du danach ja reshapest\n",
        "  x = x.reshape(1, 28, 28, 1)\n",
        "  plt.imshow(img, cmap='Greys_r')\n",
        "  plt.show()  \n",
        "  \n",
        "  #in diesem Abschnitt lassen wir unser neuronales Netz einschätzen, um welches Kleidungsstück es sich handelt; Bedenkt, dass Python ab 0 zählt, somit müsst ihr bei der ausgegebenen Zahl +1 rechnen\n",
        "  classes = model.predict(x)\n",
        "  plt.bar(range(10), classes[0])\n",
        "  plt.show()\n",
        "\n",
        "  #So sind die Labels des Datensets definiert:\n",
        "  #0 = T-shirt/top\n",
        "  #1 = Trouser\n",
        "  #2 = Pullover\n",
        "  #3 = Dress\n",
        "  #4 = Coat\n",
        "  #5 = Sandal\n",
        "  #6 = Shirt\n",
        "  #7 = Sneaker\n",
        "  #8 = Bag\n",
        "  #9 = Ankle boot\n",
        "  print(\"prediction: class\", np.argmax(classes[0]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4961 - accuracy: 0.8253\n",
            "Epoch 2/4\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3743 - accuracy: 0.8651\n",
            "Epoch 3/4\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3347 - accuracy: 0.8774\n",
            "Epoch 4/4\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3116 - accuracy: 0.8855\n",
            "[1.4985771e-05 1.3646579e-06 5.4571043e-05 1.8713448e-05 8.4433625e-05\n",
            " 2.0271538e-02 7.0539501e-04 2.1429856e-01 8.6087896e-04 7.6368964e-01]\n",
            "9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a4c400cb-2f35-4a98-870c-a424bceac612\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a4c400cb-2f35-4a98-870c-a424bceac612\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving HandtascheTest.png to HandtascheTest (2).png\n",
            "top left pixel value: [255.]\n",
            "needs to be inverted!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "prediction: class 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax9nmrD3PfWh"
      },
      "source": [
        "To do:\n",
        "Suchen und Nachprogrammieren von Tutorials:\n",
        "https://www.youtube.com/watch?v=fSBoFm0XE5E&list=PLfaNT9CeiUdJlwctZl9CQjDwiqRr4hzcH&index=231\n",
        "Erledigt\n",
        "\n",
        "https://www.youtube.com/watch?v=8Qc2fG3ZbTg&list=PLDX3iJGAOVcmttg5fX9FQYojvOK36-B5C\n",
        "Erledigt\n",
        "\n",
        "https://www.youtube.com/watch?v=YWyu8OYELUo&list=PLDX3iJGAOVcmttg5fX9FQYojvOK36-B5C&index=2\n",
        "Ausführlicher in eigenen Worten kommentieren\n",
        "\n",
        "https://www.youtube.com/watch?v=KTkjqqVilXc&list=PLDX3iJGAOVcmttg5fX9FQYojvOK36-B5C&index=3\n",
        "\n",
        "https://www.youtube.com/watch?v=OENn5okSkMs&list=PLDX3iJGAOVcmttg5fX9FQYojvOK36-B5C&index=4\n",
        "\n",
        "https://www.youtube.com/watch?v=UMwV9OGIFbk&list=PLDX3iJGAOVcmttg5fX9FQYojvOK36-B5C&index=5\n",
        "\n",
        "Suchen nach weiteren Tutorials\n",
        "\n",
        "Rechersche zur Klärung offener Fragen\n",
        "\n",
        "Verstehen der Formate von Importierten Bibliotheken z.B: Der Bildersets\n",
        "\n",
        "\n",
        "Anwendung des gelernten auf Bilder, PTN-Notationen, PTN-Dateien aus Tak\n",
        "(playtak.com)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}